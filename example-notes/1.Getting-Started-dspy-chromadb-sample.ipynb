{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'long_text': 'couch, bed, table, chair'}, {'long_text': 'computer, server, table, chair'}]\n"
     ]
    }
   ],
   "source": [
    "## pip install dspy-ai[chromadb]\n",
    "\n",
    "import chromadb\n",
    "from chromadb.utils import embedding_functions\n",
    "from dspy.retrieve.chromadb_rm import ChromadbRM\n",
    "\n",
    "## example of chormadb\n",
    "chroma_client = client = chromadb.PersistentClient(path=\"./furniture_example\")\n",
    "default_ef = embedding_functions.DefaultEmbeddingFunction()\n",
    "collection = chroma_client.get_or_create_collection(name=\"furniture\", embedding_function=default_ef)\n",
    "\n",
    "collection.add(\n",
    "    documents=[\n",
    "        \"couch, bed, table, chair\", \n",
    "        \"computer, server, table, chair\"],\n",
    "    metadatas=[\n",
    "        {\"source\": \"Bedroom\"}, \n",
    "        {\"source\": \"Office\"}\n",
    "        ],\n",
    "    ids=[\n",
    "        \"id1\", \n",
    "        \"id2\"\n",
    "    ]\n",
    ")\n",
    "\n",
    "rm = ChromadbRM(collection_name='furniture', persist_directory=\"./furniture_example\", embedding_function=default_ef)\n",
    "print(rm('comfy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dspy\n",
    "\n",
    "lm = dspy.OpenAI(model=\"gpt-3.5-turbo\")\n",
    "dspy.settings.configure(lm=lm, rm=rm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What are things in office?\n",
      "Predicted Answer: computer, server, table, chair\n",
      "Retrieved Contexts (truncated): ['computer, server, table, chair...', 'couch, bed, table, chair...']\n"
     ]
    }
   ],
   "source": [
    "from dspy import Signature, InputField, OutputField, Module, Retrieve, ChainOfThought, Prediction\n",
    "\n",
    "# Define a signature for generating answers based on the question and context\n",
    "class GenerateAnswer(Signature):\n",
    "    context = InputField(desc=\"Context containing relevant facts.\")\n",
    "    question = InputField()\n",
    "    answer = OutputField(desc=\"The generated answer, often between 1 and 5 words.\")\n",
    "\n",
    "# Define the RAG module\n",
    "class RAG(Module):\n",
    "    def __init__(self, num_passages=3):\n",
    "        super().__init__()\n",
    "        self.retrieve = Retrieve(k=num_passages)  # Number of passages to retrieve\n",
    "        self.generate_answer = ChainOfThought(GenerateAnswer)\n",
    "    \n",
    "    def forward(self, question):\n",
    "        # Use the Retrieve component to get relevant context\n",
    "        context = self.retrieve(question).passages\n",
    "        # Generate an answer based on the retrieved context and the question\n",
    "        prediction = self.generate_answer(context=context, question=question)\n",
    "        return Prediction(context=context, answer=prediction.answer)\n",
    "\n",
    "# Instantiate the RAG system\n",
    "rag_system = RAG()\n",
    "\n",
    "# Example question\n",
    "question = \"What are things in office?\"\n",
    "\n",
    "# Activate the RAG system with your question\n",
    "prediction = rag_system(question)\n",
    "\n",
    "# Print the contexts and the generated answer\n",
    "print(f\"Question: {question}\")\n",
    "print(f\"Predicted Answer: {prediction.answer}\")\n",
    "print(f\"Retrieved Contexts (truncated): {[c[:200] + '...' for c in prediction.context]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dspy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
